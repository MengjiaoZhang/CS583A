{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, Dense, Flatten, BatchNormalization, MaxPooling2D, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./input/Kannada-MNIST/test.csv\")\n",
    "train = pd.read_csv(\"./input/Kannada-MNIST/train.csv\")\n",
    "\n",
    "x = train.iloc[:,1:].values\n",
    "y = train.iloc[:,0].values\n",
    "\n",
    "x = x.reshape(x.shape[0], 28, 28, 1)\n",
    "y = to_categorical(y, 10)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.10, random_state=42) \n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.25,\n",
    "                                   height_shift_range=0.25,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.25,\n",
    "                                   horizontal_flip=False)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_kmnist():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(Dense(64))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                                          Output Shape                                    Param #           \n",
      "========================================================================================================================\n",
      "flatten_4 (Flatten)                                   (None, 784)                                     0                 \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_14 (Dense)                                      (None, 64)                                      50240             \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNormalization)           (None, 64)                                      256               \n",
      "________________________________________________________________________________________________________________________\n",
      "activation_11 (Activation)                            (None, 64)                                      0                 \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_15 (Dense)                                      (None, 128)                                     8320              \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNormalization)           (None, 128)                                     512               \n",
      "________________________________________________________________________________________________________________________\n",
      "activation_12 (Activation)                            (None, 128)                                     0                 \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_16 (Dense)                                      (None, 256)                                     33024             \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNormalization)           (None, 256)                                     1024              \n",
      "________________________________________________________________________________________________________________________\n",
      "activation_13 (Activation)                            (None, 256)                                     0                 \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_17 (Dense)                                      (None, 128)                                     32896             \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNormalization)           (None, 128)                                     512               \n",
      "________________________________________________________________________________________________________________________\n",
      "activation_14 (Activation)                            (None, 128)                                     0                 \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_18 (Dense)                                      (None, 64)                                      8256              \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNormalization)           (None, 64)                                      256               \n",
      "________________________________________________________________________________________________________________________\n",
      "activation_15 (Activation)                            (None, 64)                                      0                 \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_19 (Dense)                                      (None, 10)                                      650               \n",
      "========================================================================================================================\n",
      "Total params: 135,946\n",
      "Trainable params: 134,666\n",
      "Non-trainable params: 1,280\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "learning_rate = 5e-3\n",
    "\n",
    "model = model_kmnist()\n",
    "model.summary(120)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "106/106 [==============================] - 9s 81ms/step - loss: 0.9525 - acc: 0.6721 - val_loss: 0.2236 - val_acc: 0.8505\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 8s 78ms/step - loss: 0.4489 - acc: 0.8463 - val_loss: 0.1047 - val_acc: 0.9345\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.3731 - acc: 0.8722 - val_loss: 0.2546 - val_acc: 0.8703\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.3362 - acc: 0.8856 - val_loss: 0.2017 - val_acc: 0.9365\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.3143 - acc: 0.8934 - val_loss: 0.2154 - val_acc: 0.9332\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.3024 - acc: 0.8976 - val_loss: 0.1058 - val_acc: 0.9550\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2788 - acc: 0.9064 - val_loss: 0.1048 - val_acc: 0.9520\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2671 - acc: 0.9092 - val_loss: 0.2665 - val_acc: 0.9433\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2532 - acc: 0.9135 - val_loss: 0.0703 - val_acc: 0.9617\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2477 - acc: 0.9154 - val_loss: 0.1639 - val_acc: 0.9622\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2455 - acc: 0.9156 - val_loss: 0.0243 - val_acc: 0.9677\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2352 - acc: 0.9182 - val_loss: 0.1254 - val_acc: 0.9663\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 8s 78ms/step - loss: 0.2306 - acc: 0.9219 - val_loss: 0.0217 - val_acc: 0.9640\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2235 - acc: 0.9229 - val_loss: 0.0062 - val_acc: 0.9658\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2155 - acc: 0.9266 - val_loss: 0.0070 - val_acc: 0.9632\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2147 - acc: 0.9260 - val_loss: 0.0104 - val_acc: 0.9680\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.2127 - acc: 0.9279 - val_loss: 0.4650 - val_acc: 0.9685\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2077 - acc: 0.9299 - val_loss: 0.9644 - val_acc: 0.9603\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.2071 - acc: 0.9301 - val_loss: 0.3364 - val_acc: 0.9695\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.2002 - acc: 0.9322 - val_loss: 0.1638 - val_acc: 0.9607\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1985 - acc: 0.9330 - val_loss: 0.4551 - val_acc: 0.9683\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1958 - acc: 0.9335 - val_loss: 0.0076 - val_acc: 0.9677\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1949 - acc: 0.9349 - val_loss: 0.0161 - val_acc: 0.9668\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1857 - acc: 0.9369 - val_loss: 0.0603 - val_acc: 0.9693\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1845 - acc: 0.9366 - val_loss: 0.0689 - val_acc: 0.9725\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1905 - acc: 0.9347 - val_loss: 0.1811 - val_acc: 0.9702\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1834 - acc: 0.9384 - val_loss: 0.0141 - val_acc: 0.9710\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1813 - acc: 0.9387 - val_loss: 0.0053 - val_acc: 0.9683\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1800 - acc: 0.9391 - val_loss: 0.0204 - val_acc: 0.9687\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1790 - acc: 0.9385 - val_loss: 0.0717 - val_acc: 0.9652\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1786 - acc: 0.9392 - val_loss: 0.0197 - val_acc: 0.9708\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1783 - acc: 0.9385 - val_loss: 0.0462 - val_acc: 0.9703\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1741 - acc: 0.9394 - val_loss: 0.0013 - val_acc: 0.9758\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1710 - acc: 0.9409 - val_loss: 0.1695 - val_acc: 0.9733\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1738 - acc: 0.9410 - val_loss: 0.0127 - val_acc: 0.9768\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1687 - acc: 0.9429 - val_loss: 0.0356 - val_acc: 0.9748\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1677 - acc: 0.9421 - val_loss: 0.0098 - val_acc: 0.9757\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1658 - acc: 0.9432 - val_loss: 0.1951 - val_acc: 0.9767\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1659 - acc: 0.9430 - val_loss: 0.0292 - val_acc: 0.9703\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1638 - acc: 0.9437 - val_loss: 0.0113 - val_acc: 0.9735\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1650 - acc: 0.9432 - val_loss: 0.0623 - val_acc: 0.9743\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1609 - acc: 0.9455 - val_loss: 0.4356 - val_acc: 0.9767\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1588 - acc: 0.9461 - val_loss: 0.0146 - val_acc: 0.9743\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1610 - acc: 0.9455 - val_loss: 0.0278 - val_acc: 0.9795\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1561 - acc: 0.9469 - val_loss: 0.0525 - val_acc: 0.9740\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1623 - acc: 0.9436 - val_loss: 0.1991 - val_acc: 0.9707\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1557 - acc: 0.9467 - val_loss: 0.2991 - val_acc: 0.9770\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1520 - acc: 0.9480 - val_loss: 0.0223 - val_acc: 0.9743\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1497 - acc: 0.9492 - val_loss: 0.0513 - val_acc: 0.9798\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1567 - acc: 0.9454 - val_loss: 0.1117 - val_acc: 0.9817\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                              epochs=epochs,\n",
    "                              validation_data=valid_datagen.flow(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "106/106 [==============================] - 9s 81ms/step - loss: 0.1514 - acc: 0.9485 - val_loss: 0.0077 - val_acc: 0.9707\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1491 - acc: 0.9491 - val_loss: 0.0030 - val_acc: 0.9743\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1488 - acc: 0.9486 - val_loss: 0.0024 - val_acc: 0.9825\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1518 - acc: 0.9484 - val_loss: 0.1450 - val_acc: 0.9777\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1489 - acc: 0.9489 - val_loss: 0.0218 - val_acc: 0.9797\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1465 - acc: 0.9503 - val_loss: 0.0417 - val_acc: 0.9793\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1488 - acc: 0.9498 - val_loss: 0.0561 - val_acc: 0.9800\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1469 - acc: 0.9501 - val_loss: 0.0015 - val_acc: 0.9780\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1444 - acc: 0.9503 - val_loss: 0.1130 - val_acc: 0.9802\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1439 - acc: 0.9516 - val_loss: 0.0214 - val_acc: 0.9787\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1442 - acc: 0.9511 - val_loss: 0.1184 - val_acc: 0.9747\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1440 - acc: 0.9511 - val_loss: 0.0437 - val_acc: 0.9797\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1423 - acc: 0.9525 - val_loss: 0.0048 - val_acc: 0.9812\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1405 - acc: 0.9513 - val_loss: 0.1676 - val_acc: 0.9742\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1414 - acc: 0.9521 - val_loss: 0.0215 - val_acc: 0.9802\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1435 - acc: 0.9512 - val_loss: 0.0253 - val_acc: 0.9818\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 9s 80ms/step - loss: 0.1394 - acc: 0.9526 - val_loss: 0.0285 - val_acc: 0.9805\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1370 - acc: 0.9531 - val_loss: 0.0707 - val_acc: 0.9765\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1367 - acc: 0.9531 - val_loss: 0.0075 - val_acc: 0.9795\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1378 - acc: 0.9535 - val_loss: 0.1006 - val_acc: 0.9810\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 8s 78ms/step - loss: 0.1384 - acc: 0.9533 - val_loss: 0.0166 - val_acc: 0.9772\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1395 - acc: 0.9530 - val_loss: 0.1120 - val_acc: 0.9753\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1382 - acc: 0.9531 - val_loss: 0.0343 - val_acc: 0.9808\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1357 - acc: 0.9546 - val_loss: 0.0750 - val_acc: 0.9793\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1356 - acc: 0.9534 - val_loss: 0.0021 - val_acc: 0.9772\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1323 - acc: 0.9546 - val_loss: 0.0360 - val_acc: 0.9817\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1390 - acc: 0.9531 - val_loss: 0.0493 - val_acc: 0.9767\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1344 - acc: 0.9541 - val_loss: 0.0033 - val_acc: 0.9745\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1329 - acc: 0.9537 - val_loss: 0.0887 - val_acc: 0.9825\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1355 - acc: 0.9535 - val_loss: 0.0026 - val_acc: 0.9773\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 9s 80ms/step - loss: 0.1319 - acc: 0.9549 - val_loss: 0.2629 - val_acc: 0.9815\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1333 - acc: 0.9542 - val_loss: 0.0437 - val_acc: 0.9813\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1291 - acc: 0.9567 - val_loss: 0.0971 - val_acc: 0.9805\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1320 - acc: 0.9553 - val_loss: 0.0041 - val_acc: 0.9830\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 8s 78ms/step - loss: 0.1286 - acc: 0.9567 - val_loss: 0.0017 - val_acc: 0.9772\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1354 - acc: 0.9538 - val_loss: 0.2624 - val_acc: 0.9780\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1317 - acc: 0.9541 - val_loss: 0.0071 - val_acc: 0.9805\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1287 - acc: 0.9553 - val_loss: 0.0096 - val_acc: 0.9812\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1277 - acc: 0.9575 - val_loss: 0.0404 - val_acc: 0.9780\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1268 - acc: 0.9573 - val_loss: 0.0624 - val_acc: 0.9817\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1310 - acc: 0.9548 - val_loss: 0.0695 - val_acc: 0.9823\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1268 - acc: 0.9575 - val_loss: 0.2316 - val_acc: 0.9808\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1316 - acc: 0.9549 - val_loss: 0.0059 - val_acc: 0.9820\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1274 - acc: 0.9569 - val_loss: 5.9137e-04 - val_acc: 0.9822\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1274 - acc: 0.9569 - val_loss: 0.0170 - val_acc: 0.9853\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1246 - acc: 0.9568 - val_loss: 0.0358 - val_acc: 0.9802\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 8s 80ms/step - loss: 0.1260 - acc: 0.9575 - val_loss: 0.1227 - val_acc: 0.9793\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1264 - acc: 0.9573 - val_loss: 0.0648 - val_acc: 0.9820\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1262 - acc: 0.9574 - val_loss: 0.3246 - val_acc: 0.9802\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 8s 79ms/step - loss: 0.1230 - acc: 0.9581 - val_loss: 0.0057 - val_acc: 0.9848\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                              epochs=epochs,\n",
    "                              validation_data=valid_datagen.flow(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
